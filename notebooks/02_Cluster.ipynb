{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# Clustering employees\n",
        "\n",
        "This notebook take employee with routing informations registry and perform a cluster analysis only for employees far from their workplace more than 15 Km or 15 minutes. The subset is the sample for clustering.\n",
        "\n",
        "Out fo sample employee are marked as 'Out-of-Sample'. The final categorization is a concatenation of cluster label and province distinguish between outliers (isolate users) and cluster (agglomerates). \n",
        "\n",
        "The output of notebook is the enriched employee registry with labels attached to each employees as returned by DBSCAN algorithms. \n",
        "\n",
        "Several runs with different parameters are done in order to explore and select optimal numbers. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "import pyspark.sql.functions as F\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.cluster import DBSCAN\n",
        "\n",
        "harbour_path = 'path/to/curated_data'\n",
        "\n",
        "spark = SparkSession.builder\\\n",
        "  .master(\"local\")\\\n",
        "  .appName(\"application-name\")\\\n",
        "  .getOrCreate()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "# import data geo con distanze\n",
        "anag_dip_geo = spark.read.parquet(harbour_path + 'anag_dip_geo')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "# select users and column\n",
        "# define max distance from sede\n",
        "MAX_DISTANCE = 15 # kms\n",
        "MAX_DURATION = 15 # mins\n",
        "\n",
        "# consider only the cases where the max distance for each employee is bigger than MAX_DISTANCE km\n",
        "train = anag_dip_geo\\\n",
        "    .filter(\n",
        "        ((F.col('distanza') >= MAX_DISTANCE) | (F.col('durata') >= MAX_DURATION))\n",
        "        & (F.col('flg_regione') == 'In regione')\n",
        "    )\\\n",
        "    .select('id_dipendente', 'lat', 'lon')\\\n",
        "    .toPandas()\n",
        "\n",
        "print('Numero di lavoratori con residenza/domicilio a pi√π di {} km o {}\\' dalla sede assegnata: {}'.format(MAX_DISTANCE, MAX_DURATION, train.shape[0]))\n",
        "coords = train[['lat', 'lon']].to_numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "# perform cluster analysis\n",
        "kms_per_radian = 6371.0088 # conversion of a radiant in km\n",
        "\n",
        "# list of hyperparameter to fit\n",
        "kms = [1, 1.25, 1.5, 1.75, 2, 2.25, 2.5]\n",
        "min_samples = [3, 4, 5]\n",
        "\n",
        "# product(kms, min_samples)\n",
        "# [(x, y) for x in kms for y in min_samples]\n",
        "model_registry = []\n",
        "\n",
        "for params in [(x, y) for x in kms for y in min_samples]:\n",
        "    km = params[0]\n",
        "    epsilon = km/kms_per_radian # define the distance between two employee in a cluster\n",
        "    min_samples=params[1] # define the minimum number of members for each cluster\n",
        "\n",
        "    model = DBSCAN(\n",
        "        eps=epsilon, # max distance between two point in a cluster\n",
        "        min_samples=min_samples, # min people in a cluster\n",
        "        algorithm='ball_tree',\n",
        "        metric='haversine')\n",
        "\n",
        "    model.fit(np.radians(coords)) # needs radiant ot be fitted\n",
        "    clusters =  len(set(model.labels_))\n",
        "    outliers = len([l for l in model.labels_ if l == -1])\n",
        "    model_description = {\n",
        "        'model_name': 'model-' + 'km='+ str(km) + '-min_samples=' + str(min_samples),\n",
        "        'model': model,\n",
        "        'km': km,\n",
        "        'min_samples': min_samples,\n",
        "        'clusters': clusters,\n",
        "        'outliers': outliers\n",
        "    }\n",
        "\n",
        "    model_registry = model_registry + [model_description]\n",
        "    # print('Parameters: km={}, min_samples = {}. Found {} clusters and {} otuliers.'.format( km, min_samples, clusters, outliers)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "collapsed": false,
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "model_registry_df = pd.DataFrame(model_registry).drop(columns='model').sort_values('outliers', ascending=True).reset_index()\n",
        "display(model_registry_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "# select best model hyperparameter\n",
        "best_model_name = 'model-km=1.5-min_samples=3'\n",
        "\n",
        "# best_model_name = model_registry_df.model_name[0]\n",
        "print('Best configuration of parameters is: {}'.format(best_model_name))\n",
        "\n",
        "best_model = [m for m in model_registry if m.get('model_name')==best_model_name][0].get('model')\n",
        "train['cluster'] = best_model.labels_.astype(str)\n",
        "train.cluster.value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "# write back data\n",
        "# dipendenti con cluster\n",
        "# assembly data back\n",
        "anag_dip_geo_clus = anag_dip_geo\\\n",
        "    .join(\n",
        "        spark.createDataFrame(train).select('id_dipendente', 'cluster'), \n",
        "        on='id_dipendente', \n",
        "        how='left'\n",
        "        )\\\n",
        "    .withColumn(\n",
        "        'label_type', F.when(F.col('cluster').isNull(), 'Out of Sample')\\\n",
        "            .when(F.col('cluster')=='-1', 'Outlier')\\\n",
        "            .otherwise(F.lit('Cluster'))\n",
        "    )\\\n",
        "    .withColumn(\n",
        "        'label', F.when(F.col('label_type') == 'Cluster',\n",
        "            F.concat(F.col('label_type'), F.lit(' '), F.col('cluster'), F.lit(' ('), F.col('provincia'), F.lit(')'))\n",
        "        )\\\n",
        "        .otherwise(\n",
        "            F.concat(F.col('label_type'), F.lit(' ('), F.col('provincia'), F.lit(')'))\n",
        "        )\n",
        "    )\n",
        "\n",
        "# anag_clus"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "anag_dip_geo_clus.count()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "anag_dip_geo_clus.write.parquet(harbour_path + 'anag_dip_geo_clus', mode='overwrite')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "# anag_clus = anag_dip_geo_clus\\\n",
        "#     .groupBy('label', 'label_type', 'provincia')\\\n",
        "#     .agg(\n",
        "#         F.count('id_dipendente').alias('n_dipendenti'),\n",
        "#         F.avg('lat').alias('avg_lat'),\n",
        "#         F.avg('lon').alias('avg_lon'),\n",
        "        \n",
        "#         )\n",
        "\n",
        "# anag_clus.count()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "# anag_clus.write.parquet(harbour_path + 'v2/anag_clus', mode='overwrite')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "description": null,
    "interpreter": {
      "hash": "a2176ed0753c912996b883d7e74abc00192f41831e7e7297deb7d9eae49ab795"
    },
    "kernelspec": {
      "display_name": "Python 3.9.0 ('spark-py')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.0"
    },
    "save_output": true
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
